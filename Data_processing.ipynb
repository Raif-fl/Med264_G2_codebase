{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "available-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "module_path='preprocessing/day_intervals_preproc'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "module_path='utils'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "module_path='preprocessing'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import day_intervals_cohort_v2\n",
    "from day_intervals_cohort_v2 import *\n",
    "\n",
    "import data_generation_icu\n",
    "\n",
    "import feature_selection_icu\n",
    "from feature_selection_icu import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import ml_models\n",
    "# from ml_models import *\n",
    "\n",
    "# import dl_train\n",
    "# from dl_train import *\n",
    "\n",
    "# import tokenization\n",
    "# from tokenization import *\n",
    "\n",
    "# import behrt_train\n",
    "# from behrt_train import *\n",
    "\n",
    "# import evaluation\n",
    "# import fairness\n",
    "# import callibrate_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-tissue",
   "metadata": {},
   "source": [
    "## 1. DATA EXTRACTION\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "broke-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.dirname(os.path.abspath('UserInterface.ipynb'))\n",
    "version_path=\"mimiciv/2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "republican-freight",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========MIMIC-IV v2.0============\n",
      "EXTRACTING FOR: | ICU | READMISSION DUE TO J44 | 30 | \n",
      "[ READMISSION DUE TO J44 ]\n",
      "Index(['subject_id', 'stay_id', 'hadm_id', 'intime', 'outtime', 'los',\n",
      "       'min_valid_year', 'dod', 'Age', 'gender', 'race', 'insurance'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 5217/5217 [00:15<00:00, 341.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ READMISSION LABELS FINISHED ]\n",
      "[ COHORT SUCCESSFULLY SAVED ]\n",
      "[ SUMMARY SUCCESSFULLY SAVED ]\n",
      "Readmission FOR ICU DATA\n",
      "# Admission Records: 7346\n",
      "# Patients: 5217\n",
      "# Positive cases: 1137\n",
      "# Negative cases: 6209\n"
     ]
    }
   ],
   "source": [
    "cohort_output = day_intervals_cohort_v2.extract_data(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-stadium",
   "metadata": {},
   "source": [
    "## 2. FEATURE SELECTION\n",
    "All features will be saved in **./data/features/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "native-covering",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EXTRACTING CHART EVENTS DATA]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [07:52, 14.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Unique Events:   412\n",
      "# Admissions:   7345\n",
      "Total rows 7568035\n",
      "[SUCCESSFULLY SAVED CHART EVENTS DATA]\n"
     ]
    }
   ],
   "source": [
    "feature_icu(cohort_output, version_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-captain",
   "metadata": {},
   "source": [
    "## 3. SUMMARY OF FEATURES\n",
    "\n",
    "This step will generate summary of all features extracted so far.<br>\n",
    "It will save summary files in **./data/summary/**<br>\n",
    "- These files provide summary about **mean frequency** of medical codes per admission.<br>\n",
    "- It also provides **total occurrence count** of each medical code.<br>\n",
    "- For labs and chart events it will also provide <br>**missing %** which tells how many rows for a certain medical code has missing value.\n",
    "\n",
    "Please use this information to further refine your cohort by selecting <br>which medical codes in each feature you want to keep and <br>which codes you would like to remove for downstream analysis tasks.\n",
    "\n",
    "**Please run below cell to generate summary files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "thick-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GENERATING FEATURE SUMMARY]\n",
      "[SUCCESSFULLY SAVED FEATURE SUMMARY]\n"
     ]
    }
   ],
   "source": [
    "generate_summary_icu(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-architecture",
   "metadata": {},
   "source": [
    "## 4. Feature Selection\n",
    "\n",
    "based on the files generated in previous step and other infromation gathered by you,<br>\n",
    "Please select which medical codes you want to include in this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54828748-ee11-47bd-9c4e-18e7a388ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get the path to the file. \n",
    "sum_path = \"data/summary/chart_features.csv\"\n",
    "\n",
    "# Then use pandas to load up the dataframe.\n",
    "feats = pd.read_csv(sum_path)\n",
    "\n",
    "# Set up all of the medical codes you want to save\n",
    "to_keep = [220045, 220179, 223761, 220210, 220277]\n",
    "\n",
    "keeps = []\n",
    "for i in feats[\"itemid\"]:\n",
    "    keeps.append(i in to_keep)\n",
    "\n",
    "# Filter feats\n",
    "feat_filt = feats[keeps]\n",
    "\n",
    "# Save the features of interest\n",
    "feat_filt.to_csv(sum_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "perceived-python",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FEATURE SELECTION CHART EVENTS DATA]\n",
      "Total number of rows 2556262\n",
      "[SUCCESSFULLY SAVED CHART EVENTS DATA]\n"
     ]
    }
   ],
   "source": [
    "# This will perform the feature selection based on your subsetted list of features. \n",
    "features_selection_icu(cohort_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-director",
   "metadata": {},
   "source": [
    "## 5. CLEANING OF FEATURES\n",
    "We chose not to perform any additional outlier detection here, as we did not want to lower our sample size even further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "impossible-mailman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROCESSING CHART EVENTS DATA]\n",
      "Total number of rows 2527135\n",
      "[SUCCESSFULLY SAVED CHART EVENTS DATA]\n"
     ]
    }
   ],
   "source": [
    "thresh=0\n",
    "clean_chart='No outlier detection'\n",
    "impute_outlier_chart=False\n",
    "thresh=98\n",
    "left_thresh=0\n",
    "preprocess_features_icu(cohort_output,clean_chart,impute_outlier_chart,thresh,left_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-academy",
   "metadata": {},
   "source": [
    "## 6. Time-Series Representation\n",
    "\n",
    "- We select the last 72 hours of the first admission as the time-series data we want to include for this study.\n",
    "\n",
    "- the selection of bucket size is arbitrary as all data over those 72 hours will be aggregated in the final dataset.\n",
    "\n",
    "Following data generation, the seperate getXY notebook is used to create the final datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "indie-appendix",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ READ COHORT ]\n",
      "[ ======READING CHART EVENTS ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:23, 23.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ READ ALL FEATURES ]\n",
      "[ PROCESSED TIME SERIES TO EQUAL LENGTH  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 72/72 [00:00<00:00, 159.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket 1\n",
      "[ PROCESSED TIME SERIES TO EQUAL TIME INTERVAL ]\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2538/2538 [00:44<00:00, 56.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ SUCCESSFULLY SAVED DATA DICTIONARIES ]\n"
     ]
    }
   ],
   "source": [
    "predW=0\n",
    "bucket = 1\n",
    "include = 72\n",
    "impute=False\n",
    "gen=data_generation_icu.Generator(cohort_output,impute,include,bucket,predW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f136975d-f121-40bc-b994-02b72723dce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56083170-c2a6-4261-b3b2-9ca4a1a65518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
